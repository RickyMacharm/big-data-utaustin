{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "### Rohan Nagar\n",
    "\n",
    "*Note: This assignment is done in Python 3.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function takes in a pandas dataframe and returns a preprocessed form of the data.\n",
    "# Deals with missing values and converts categorical data to a numerical representation.\n",
    "def preprocess_data(data):\n",
    "    data = data.replace('?', np.nan)\n",
    "    \n",
    "    # Replace missing categorical data with most-frequent and missing numerical data with mean\n",
    "    data = data.fillna(pd.Series(\n",
    "            [data[c].value_counts().index[0] if data[c].dtype == np.dtype('O') else data[c].mean() for c in data],\n",
    "            index=data.columns))\n",
    "\n",
    "    # Convert categorical data into numerical labels\n",
    "    for c in data:\n",
    "        if data[c].dtype == np.dtype('O'):\n",
    "            encoder = preprocessing.LabelEncoder()\n",
    "            data[c] = encoder.fit_transform(data[c])\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Question (Missing Data)\n",
    "\n",
    "1. I dealt with missing data in two different ways. If the data was categorical, then I filled in that missing categorical data with the most frequently occuring type. For example, if a row is missing the `workclass` information, and `Private` is the most common `workclass`, then that row will be filled in with the value `Private`.\n",
    "\n",
    "  The second way I dealt with missing data was if it was numerical. In this case, if a row was missing data, it was filled in with the average of all available data in that column. For example, if a row is missing the `capital-gain` feature, then the average of `capital-gain` from all the data will be used to fill in the row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - SVMs\n",
    "\n",
    "First, let's read in the training data and deal with missing values by calling our `preprocess_data` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0   39          6   77516          9             13               4   \n",
       "1   50          5   83311          9             13               2   \n",
       "2   38          3  215646         11              9               0   \n",
       "3   53          3  234721          1              7               2   \n",
       "4   28          3  338409          9             13               2   \n",
       "\n",
       "   occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0           0             1     4    1          2174             0   \n",
       "1           3             0     4    1             0             0   \n",
       "2           5             1     4    1             0             0   \n",
       "3           5             0     2    1             0             0   \n",
       "4           9             5     2    0             0             0   \n",
       "\n",
       "   hours-per-week  native-country  salary  \n",
       "0              40              38       0  \n",
       "1              13              38       0  \n",
       "2              40              38       0  \n",
       "3              40              38       0  \n",
       "4              40               4       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data and preprocess\n",
    "data = pd.read_csv(\"../dataset/train.data\", sep=', ', header=None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'salary'], engine='python')\n",
    "data = preprocess_data(data)\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll split the data into train and validation. We are going to use a standard percentage split. We are also going to try different test sizes to see which gives us the best accuracy. These sizes are 30%, 40%, 50%, 60%, and 70%; where those percentages represent the test size. We'll run a standard SVM RBF model to determine the best accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy with a split test size of 0.3: 0.7631282628723514\n",
      "SVM Accuracy with a split test size of 0.4: 0.7596928982725528\n",
      "SVM Accuracy with a split test size of 0.5: 0.7589214421718568\n",
      "SVM Accuracy with a split test size of 0.6: 0.7595331934278549\n",
      "SVM Accuracy with a split test size of 0.7: 0.760277278111701\n"
     ]
    }
   ],
   "source": [
    "# Slice columns into independent and dependent data\n",
    "indep_data, dep_data = data.iloc[:, :14], data.iloc[:, 14]\n",
    "\n",
    "sizes = [0.30, 0.40, 0.50, 0.60, 0.70]\n",
    "for s in sizes:\n",
    "    # Split into train and validation\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(indep_data, dep_data, test_size=s, random_state=42)\n",
    "    \n",
    "    # Scale the data\n",
    "    temp_scale = preprocessing.StandardScaler()\n",
    "    X_train, X_validation = temp_scale.fit_transform(X_train), temp_scale.transform(X_valid)\n",
    "    \n",
    "    # Run a test SVM so that we can see the accuracy on the validation set\n",
    "    temp_svm = SVC()\n",
    "    temp_svm.fit(X_train, y_train)\n",
    "    temp_score = accuracy_score(temp_svm.predict(X_valid), y_valid)\n",
    "    print(\"SVM Accuracy with a split test size of {}: {}\".format(s, temp_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, a split test size of 0.30 gave us the best accuracy on the validation set. So, let's use that size to do our actual split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split into train and validation\n",
    "indep_train, indep_validation, dep_train, dep_validation = train_test_split(indep_data, dep_data, test_size=0.30, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scale = preprocessing.StandardScaler()\n",
    "indep_train, indep_validation = scale.fit_transform(indep_train), scale.transform(indep_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='svm_kernel'></a>\n",
    "Now to train SVMs! One each of RBF, Linear, and Polynomial. After that, we'll play with 3 other parameters to the SVM and then use the best model we can by playing with the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Accuracy: 0.8505476507319071\n",
      "Linear Accuracy: 0.8216808271061521\n",
      "Polynomial Accuracy MSE: 0.8458388780837343\n"
     ]
    }
   ],
   "source": [
    "svm_rbf = SVC(kernel='rbf')\n",
    "svm_linear = SVC(kernel='linear')\n",
    "svm_poly = SVC(kernel='poly')\n",
    "\n",
    "svm_rbf.fit(indep_train, dep_train)\n",
    "svm_linear.fit(indep_train, dep_train)\n",
    "svm_poly.fit(indep_train, dep_train)\n",
    "\n",
    "rbf_score = accuracy_score(svm_rbf.predict(indep_validation), dep_validation)\n",
    "linear_score = accuracy_score(svm_linear.predict(indep_validation), dep_validation)\n",
    "poly_score = accuracy_score(svm_poly.predict(indep_validation), dep_validation)\n",
    "\n",
    "print(\"RBF Accuracy: {}\".format(rbf_score))\n",
    "print(\"Linear Accuracy: {}\".format(linear_score))\n",
    "print(\"Polynomial Accuracy MSE: {}\".format(poly_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='svm_param_tweaks'></a>\n",
    "It looks like the RBF kernel gave us the best accuracy on the validation set, with the polynomial kernel close behind. The linear kernel is the worst of the three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy for C=0.1: 0.8430750332685024\n",
      "SVM Accuracy for C=0.25: 0.8472719828027434\n",
      "SVM Accuracy for C=0.5: 0.8510594738458389\n",
      "SVM Accuracy for C=1.0: 0.8505476507319071\n",
      "SVM Accuracy for C=1.5: 0.8507523799774798\n",
      "SVM Accuracy for C=2.0: 0.8513665677141979\n",
      "SVM Accuracy for C=4.0: 0.8515712969597707\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAERCAYAAACD9ivUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD6yN3RXupvOYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c53fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c6f3fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train some more SVMs, changing different parameters\n",
    "# Change C parameter\n",
    "params = [0.1, 0.25, 0.5, 1.0, 1.5, 2.0, 4.0]\n",
    "accuracy = []\n",
    "\n",
    "for p in params:\n",
    "    svm = SVC(C=p)\n",
    "    svm.fit(indep_train, dep_train)\n",
    "    score = accuracy_score(svm.predict(indep_validation), dep_validation)\n",
    "    accuracy.append(score)\n",
    "    print(\"SVM Accuracy for C={}: {}\".format(p, score))\n",
    "    \n",
    "plt.scatter(params, accuracy, color='black')\n",
    "plt.xlabel('C value')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `C` parameter in the SVC model reflects a tradeoff between reducing misclassification and model simplicity. With a lower `C` value, the decision surface is smooth, but there are potentiall more misclassifications. With a high `C` value, the model will try to classify all training data correctly by giving the model more freedom to select more support vectors.\n",
    "\n",
    "As we can see from the plot, accuracy improves dramatically up to `C=0.5`, which is expected. However, after that the accuracy levels off. From this, we can assume that selecting more support vectors does not help improve accuracy on this set of data. Since there isn't much of a difference from 2.0 to 4.0, we will use a value of 2.0 in our final model to reduce complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy for gamma=0.1: 0.8517760262053434\n",
      "SVM Accuracy for gamma=0.25: 0.8464530658204524\n",
      "SVM Accuracy for gamma=0.5: 0.8358071450506704\n",
      "SVM Accuracy for gamma=1.0: 0.8193264407820657\n",
      "SVM Accuracy for gamma=1.5: 0.8092947077490019\n",
      "SVM Accuracy for gamma=2.0: 0.8005937148121609\n",
      "SVM Accuracy for gamma=4.0: 0.7841130105435562\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAERCAYAAACO6FuTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e4a3240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c6aff28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change gamma parameter\n",
    "params = [0.1, 0.25, 0.5, 1.0, 1.5, 2.0, 4.0]\n",
    "accuracy = []\n",
    "\n",
    "for p in params:\n",
    "    svm = SVC(gamma=p)\n",
    "    svm.fit(indep_train, dep_train)\n",
    "    score = accuracy_score(svm.predict(indep_validation), dep_validation)\n",
    "    accuracy.append(score)\n",
    "    print(\"SVM Accuracy for gamma={}: {}\".format(p, score))\n",
    "    \n",
    "plt.scatter(params, accuracy, color='black')\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `gamma` parameter in the SVC model defines how \"far\" a single data point influences the model. Low values of `gamma` means that a single data example will reach \"far\", while a high value means \"close\". Intuitively, this means that low `gamma` values will produce a higher accuracy.\n",
    "\n",
    "This can be seen in the plot above. As `gamma` increases, the accuracy decreases. Thus, we want a small value of `gamma` for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy without probability: 0.8505476507319071\n",
      "SVM Accuracy with probability: 0.8505476507319071\n"
     ]
    }
   ],
   "source": [
    "# Change probability parameter \n",
    "svm = SVC() # default is False\n",
    "svm.fit(indep_train, dep_train)\n",
    "true_shrinking_score = accuracy_score(svm.predict(indep_validation), dep_validation)\n",
    "print(\"SVM Accuracy without probability: {}\".format(true_shrinking_score))\n",
    "\n",
    "svm = SVC(probability=True)\n",
    "svm.fit(indep_train, dep_train)\n",
    "false_shrinking_score = accuracy_score(svm.predict(indep_validation), dep_validation)\n",
    "print(\"SVM Accuracy with probability: {}\".format(false_shrinking_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='svm_validation_result'></a>\n",
    "The `probability` parameter decides whether to use probability estimates when fitting the model or not. Turning on probability estimates slows down the fitting of the model since it has to calcuate the probability estimates.\n",
    "\n",
    "However, as we can see from the results above, this had no effect on the accuracy of our model in this case. It seems that the data is well represented without using probability estimates.\n",
    "\n",
    "Let's now combine our knowledge of how these parameters affect the accuracy to produce a final model that we will run the test data on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy on validation: 0.8507523799774798\n"
     ]
    }
   ],
   "source": [
    "# This is the final model\n",
    "svm = SVC(kernel='rbf', C=2.0, gamma=0.1, probability=False)\n",
    "svm.fit(indep_train, dep_train)\n",
    "score = accuracy_score(svm.predict(indep_validation), dep_validation)\n",
    "print(\"SVM Accuracy on validation: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='svm_test_result'></a>\n",
    "Finally, let's run our final model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16281, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>226802</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>89814</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>336951</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>160323</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>103497</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0   25          3  226802          1              7               4   \n",
       "1   38          3   89814         11              9               2   \n",
       "2   28          1  336951          7             12               2   \n",
       "3   44          3  160323         15             10               2   \n",
       "4   18          3  103497         15             10               4   \n",
       "\n",
       "   occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0           6             3     2    1             0             0   \n",
       "1           4             0     4    1             0             0   \n",
       "2          10             0     4    1             0             0   \n",
       "3           6             0     2    1          7688             0   \n",
       "4           9             3     4    0             0             0   \n",
       "\n",
       "   hours-per-week  native-country  salary  \n",
       "0              40              37       0  \n",
       "1              50              37       0  \n",
       "2              40              37       1  \n",
       "3              40              37       1  \n",
       "4              30              37       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring in test data and process it\n",
    "test_data = pd.read_csv(\"../dataset/test.data\", sep=', ', header=None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'salary'], engine='python')\n",
    "test_data = preprocess_data(test_data)\n",
    "\n",
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy on test data: 0.8505620047908605\n"
     ]
    }
   ],
   "source": [
    "# Split and transform the independent data to run on the model\n",
    "indep_test_data, dep_test_data = test_data.iloc[:, :14], test_data.iloc[:, 14]\n",
    "indep_test_data = scale.transform(indep_test_data)\n",
    "\n",
    "score = accuracy_score(svm.predict(indep_test_data), dep_test_data)\n",
    "print(\"SVM Accuracy on test data: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Questions\n",
    "\n",
    "1. The data was split using a standard percentage. The percentages that were tried were 30%, 40%, 50%, 60%, and 70%; where those percentages represent the test size. The 30% split gave the best accuracy on the validation set.\n",
    "2. The accuracy for each kernel is displayed in the relevant code above. [[Here]](#svm_kernel)\n",
    "3. Three other parameters were tweaked and the plots or results are displayed in the relevant code above. [[Here]](#svm_param_tweaks)\n",
    "\n",
    "##### Final SVM Questions\n",
    "1. The final parameters used in my model were:\n",
    "    - kernel: RBF\n",
    "    - C: 2.0\n",
    "    - gamma: 0.1\n",
    "    - probability: False\n",
    "2. I did not remove any features. I felt that all of the features in the data were meaningful features that could provide some insight to the salary of the person. Therefore, I wanted to use all of the features so as to not miss something that the data could tell me.\n",
    "3. The accuracy for the final model on the validation set is displayed in the relevant code above. [[Here]](#svm_validation_result)\n",
    "4. The accuracy for the final model on the test data is displayed in the relevant code above. [[Here]](#svm_test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - AdaBoostClassifier\n",
    "\n",
    "<a id='boost_estimators'></a>\n",
    "Next we're going to use the AdaBoostClassifier to fit our model. We'll try 8 different numbers of estimators and 10 different learning rates to try and get the best possible model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost Accuracy for 10 estimators: 0.8513665677141979\n",
      "Boost Accuracy for 20 estimators: 0.8575084450813799\n",
      "Boost Accuracy for 30 estimators: 0.8596581021598936\n",
      "Boost Accuracy for 40 estimators: 0.860067560651039\n",
      "Boost Accuracy for 50 estimators: 0.8616030299928344\n",
      "Boost Accuracy for 100 estimators: 0.8660047087726481\n",
      "Boost Accuracy for 200 estimators: 0.8678472719828028\n",
      "Boost Accuracy for 400 estimators: 0.8724536800081891\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEMCAYAAAA8vjqRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c6a96a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f6c0518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimators = [10, 20, 30, 40, 50, 100, 200, 400]\n",
    "accuracy = []\n",
    "\n",
    "for n in estimators:\n",
    "    boost = AdaBoostClassifier(n_estimators=n)\n",
    "    boost.fit(indep_train, dep_train)\n",
    "    score = accuracy_score(boost.predict(indep_validation), dep_validation)\n",
    "    accuracy.append(score)\n",
    "    print(\"Boost Accuracy for {} estimators: {}\".format(n, score))\n",
    "    \n",
    "plt.scatter(estimators, accuracy, color='black')\n",
    "plt.xlabel('estimators')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='boost_learning_rate'></a>\n",
    "We can see from the plot that as we increase the estimators, the accuracy increases as well. However, it starts to taper off as we get to a large number of estimators. This intuitively makes sense, because more estimators helps more with larger dataset sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost Accuracy for learning rate of 0.1: 0.8446105026102979\n",
      "Boost Accuracy for learning rate of 0.25: 0.8542327771522162\n",
      "Boost Accuracy for learning rate of 0.4: 0.8558706111167981\n",
      "Boost Accuracy for learning rate of 0.5: 0.8595557375371071\n",
      "Boost Accuracy for learning rate of 0.6: 0.8609888422561163\n",
      "Boost Accuracy for learning rate of 0.75: 0.8588391851776026\n",
      "Boost Accuracy for learning rate of 1.0: 0.8616030299928344\n",
      "Boost Accuracy for learning rate of 1.5: 0.8591462790459617\n",
      "Boost Accuracy for learning rate of 2.0: 0.7631282628723514\n",
      "Boost Accuracy for learning rate of 5.0: 0.2368717371276487\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAERCAYAAAB7FtAjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c70fa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cbe3ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rates = [0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 1.0, 1.5, 2.0, 5.0]\n",
    "accuracy = []\n",
    "\n",
    "for rate in learning_rates:\n",
    "    boost = AdaBoostClassifier(learning_rate=rate)\n",
    "    boost.fit(indep_train, dep_train)\n",
    "    score = accuracy_score(boost.predict(indep_validation), dep_validation)\n",
    "    accuracy.append(score)\n",
    "    print(\"Boost Accuracy for learning rate of {}: {}\".format(rate, score))\n",
    "    \n",
    "plt.scatter(learning_rates, accuracy, color='black')\n",
    "plt.xlabel('learning rates')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the plot that most of the lower learning rates keep the accuracy at around the same value. It actually hits a peak at a learning rate of 1.5. After that, the accuracy starts to tank and hits really low at a learning rate of 5.0. Again, this makes sense beacuse with a high learning rate you are likely to overshoot the true model.\n",
    "\n",
    "<a id='boost_validation_result'></a>\n",
    "Let's use what we've learned to fit a final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost Accuracy on validation set: 0.8691780120790255\n"
     ]
    }
   ],
   "source": [
    "# This is the final model\n",
    "final_boost = AdaBoostClassifier(n_estimators=600, learning_rate=1.72)\n",
    "final_boost.fit(indep_train, dep_train)\n",
    "\n",
    "score = accuracy_score(final_boost.predict(indep_validation), dep_validation)\n",
    "print(\"Boost Accuracy on validation set: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='boost_test_result'></a>\n",
    "Lastly, let's run the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost Accuracy on test data: 0.8689269700878325\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(final_boost.predict(indep_test_data), dep_test_data)\n",
    "print(\"Boost Accuracy on test data: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Questions\n",
    "\n",
    "1. The plot as the estimators change is displayed in the relevant code above. [[Here]](#boost_estimators)\n",
    "2. The plot as the learning rate changes is displayed in the relevant code above. [[Here]](#boost_learning_rate)\n",
    "\n",
    "##### Final AdaBoostClassifier Questions\n",
    "1. The final parameters I used in my model were:\n",
    "    - n_estimators: 600\n",
    "    - learning_rate: 1.72\n",
    "2. The accuracy for the final model on the validation set is displayed in the relevant code above. [[Here]](#boost_validation_result)\n",
    "3. The accuracy for the final model on the test data is displayed in the relevant code above. [[Here]](#boost_test_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
